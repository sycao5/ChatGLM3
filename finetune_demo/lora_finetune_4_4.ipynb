{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 单卡GPU 进行 ChatGLM3-6B模型 LORA 高效微调\n",
        "本 Cookbook 将带领开发者使用 `AdvertiseGen` 对 ChatGLM3-6B 数据集进行 lora微调，使其具备专业的广告生成能力。\n",
        "\n",
        "## 硬件需求\n",
        "显存：24GB\n",
        "显卡架构：安培架构（推荐）\n",
        "内存：16GB"
      ],
      "metadata": {
        "collapsed": false,
        "id": "89b89f64d8f8053d"
      },
      "id": "89b89f64d8f8053d"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. 准备数据集\n",
        "我们使用 AdvertiseGen 数据集来进行微调。从 [Google Drive](https://drive.google.com/file/d/13_vf0xRTQsyneRKdD1bZIr93vBGOczrk/view?usp=sharing) 或者 [Tsinghua Cloud](https://cloud.tsinghua.edu.cn/f/b3f119a008264b1cabd1/?dl=1) 下载处理好的 AdvertiseGen 数据集，将解压后的 AdvertiseGen 目录放到本目录的 `/data/` 下, 例如。\n",
        "> /media/zr/Data/Code/ChatGLM3/finetune_demo/data/AdvertiseGen\n",
        "\n",
        "接着，运行本代码来切割数据集"
      ],
      "metadata": {
        "collapsed": false,
        "id": "a7bd9a514ed09ea6"
      },
      "id": "a7bd9a514ed09ea6"
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gnWe0uQh13Lw",
        "outputId": "9b5852a2-94ae-4b4b-e0c0-54932e467907"
      },
      "id": "gnWe0uQh13Lw",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "      name=fn, length=len(uploaded[fn])))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "id": "GLvRMnPW_Qt7",
        "outputId": "58847940-7961-403b-8a74-e9efbd274d6d"
      },
      "id": "GLvRMnPW_Qt7",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-2017d555-dac5-4b6c-869a-31da3ea5bb34\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-2017d555-dac5-4b6c-869a-31da3ea5bb34\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving requirements.txt to requirements (1).txt\n",
            "User uploaded file \"requirements (1).txt\" with length 160 bytes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G_0iPA5Q_XPo",
        "outputId": "d05b4006-a7c4-44be-b7f9-3590963f1936"
      },
      "id": "G_0iPA5Q_XPo",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: jieba>=0.42.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 1)) (0.42.1)\n",
            "Requirement already satisfied: ruamel_yaml>=0.18.6 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 2)) (0.18.6)\n",
            "Requirement already satisfied: rouge_chinese>=1.0.3 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 3)) (1.0.3)\n",
            "Requirement already satisfied: jupyter>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 4)) (1.0.0)\n",
            "Requirement already satisfied: datasets>=2.17.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 5)) (2.18.0)\n",
            "Requirement already satisfied: peft>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 6)) (0.10.0)\n",
            "Requirement already satisfied: transformers>=4.38.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 7)) (4.38.2)\n",
            "Requirement already satisfied: deepspeed==0.13.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 8)) (0.13.1)\n",
            "Requirement already satisfied: mpi4py>=3.1.5 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 9)) (3.1.5)\n",
            "Requirement already satisfied: hjson in /usr/local/lib/python3.10/dist-packages (from deepspeed==0.13.1->-r requirements.txt (line 8)) (3.1.0)\n",
            "Requirement already satisfied: ninja in /usr/local/lib/python3.10/dist-packages (from deepspeed==0.13.1->-r requirements.txt (line 8)) (1.11.1.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from deepspeed==0.13.1->-r requirements.txt (line 8)) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from deepspeed==0.13.1->-r requirements.txt (line 8)) (24.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from deepspeed==0.13.1->-r requirements.txt (line 8)) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from deepspeed==0.13.1->-r requirements.txt (line 8)) (9.0.0)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.10/dist-packages (from deepspeed==0.13.1->-r requirements.txt (line 8)) (2.6.4)\n",
            "Requirement already satisfied: pynvml in /usr/local/lib/python3.10/dist-packages (from deepspeed==0.13.1->-r requirements.txt (line 8)) (11.5.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from deepspeed==0.13.1->-r requirements.txt (line 8)) (2.2.1+cu121)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from deepspeed==0.13.1->-r requirements.txt (line 8)) (4.66.2)\n",
            "Requirement already satisfied: ruamel.yaml.clib>=0.2.7 in /usr/local/lib/python3.10/dist-packages (from ruamel_yaml>=0.18.6->-r requirements.txt (line 2)) (0.2.8)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from rouge_chinese>=1.0.3->-r requirements.txt (line 3)) (1.16.0)\n",
            "Requirement already satisfied: notebook in /usr/local/lib/python3.10/dist-packages (from jupyter>=1.0.0->-r requirements.txt (line 4)) (6.5.5)\n",
            "Requirement already satisfied: qtconsole in /usr/local/lib/python3.10/dist-packages (from jupyter>=1.0.0->-r requirements.txt (line 4)) (5.5.1)\n",
            "Requirement already satisfied: jupyter-console in /usr/local/lib/python3.10/dist-packages (from jupyter>=1.0.0->-r requirements.txt (line 4)) (6.1.0)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.10/dist-packages (from jupyter>=1.0.0->-r requirements.txt (line 4)) (6.5.4)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.10/dist-packages (from jupyter>=1.0.0->-r requirements.txt (line 4)) (5.5.6)\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.10/dist-packages (from jupyter>=1.0.0->-r requirements.txt (line 4)) (7.7.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets>=2.17.1->-r requirements.txt (line 5)) (3.13.3)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.17.1->-r requirements.txt (line 5)) (14.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets>=2.17.1->-r requirements.txt (line 5)) (0.6)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.17.1->-r requirements.txt (line 5)) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets>=2.17.1->-r requirements.txt (line 5)) (2.0.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.17.1->-r requirements.txt (line 5)) (2.31.0)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets>=2.17.1->-r requirements.txt (line 5)) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets>=2.17.1->-r requirements.txt (line 5)) (0.70.16)\n",
            "Requirement already satisfied: fsspec[http]<=2024.2.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.17.1->-r requirements.txt (line 5)) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.17.1->-r requirements.txt (line 5)) (3.9.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.4 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.17.1->-r requirements.txt (line 5)) (0.20.3)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.17.1->-r requirements.txt (line 5)) (6.0.1)\n",
            "Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from peft>=0.10.0->-r requirements.txt (line 6)) (0.28.0)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from peft>=0.10.0->-r requirements.txt (line 6)) (0.4.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.38.1->-r requirements.txt (line 7)) (2023.12.25)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.38.1->-r requirements.txt (line 7)) (0.15.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.17.1->-r requirements.txt (line 5)) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.17.1->-r requirements.txt (line 5)) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.17.1->-r requirements.txt (line 5)) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.17.1->-r requirements.txt (line 5)) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.17.1->-r requirements.txt (line 5)) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.17.1->-r requirements.txt (line 5)) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.4->datasets>=2.17.1->-r requirements.txt (line 5)) (4.10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets>=2.17.1->-r requirements.txt (line 5)) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets>=2.17.1->-r requirements.txt (line 5)) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets>=2.17.1->-r requirements.txt (line 5)) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets>=2.17.1->-r requirements.txt (line 5)) (2024.2.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed==0.13.1->-r requirements.txt (line 8)) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed==0.13.1->-r requirements.txt (line 8)) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed==0.13.1->-r requirements.txt (line 8)) (3.1.3)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed==0.13.1->-r requirements.txt (line 8)) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed==0.13.1->-r requirements.txt (line 8)) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed==0.13.1->-r requirements.txt (line 8)) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed==0.13.1->-r requirements.txt (line 8)) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed==0.13.1->-r requirements.txt (line 8)) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed==0.13.1->-r requirements.txt (line 8)) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed==0.13.1->-r requirements.txt (line 8)) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed==0.13.1->-r requirements.txt (line 8)) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed==0.13.1->-r requirements.txt (line 8)) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed==0.13.1->-r requirements.txt (line 8)) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed==0.13.1->-r requirements.txt (line 8)) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed==0.13.1->-r requirements.txt (line 8)) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->deepspeed==0.13.1->-r requirements.txt (line 8)) (12.4.127)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.10/dist-packages (from ipykernel->jupyter>=1.0.0->-r requirements.txt (line 4)) (0.2.0)\n",
            "Requirement already satisfied: ipython>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from ipykernel->jupyter>=1.0.0->-r requirements.txt (line 4)) (7.34.0)\n",
            "Requirement already satisfied: traitlets>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from ipykernel->jupyter>=1.0.0->-r requirements.txt (line 4)) (5.7.1)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.10/dist-packages (from ipykernel->jupyter>=1.0.0->-r requirements.txt (line 4)) (6.1.12)\n",
            "Requirement already satisfied: tornado>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipykernel->jupyter>=1.0.0->-r requirements.txt (line 4)) (6.3.3)\n",
            "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets->jupyter>=1.0.0->-r requirements.txt (line 4)) (3.6.6)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets->jupyter>=1.0.0->-r requirements.txt (line 4)) (3.0.10)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-console->jupyter>=1.0.0->-r requirements.txt (line 4)) (3.0.43)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from jupyter-console->jupyter>=1.0.0->-r requirements.txt (line 4)) (2.16.1)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter>=1.0.0->-r requirements.txt (line 4)) (4.9.4)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter>=1.0.0->-r requirements.txt (line 4)) (4.12.3)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter>=1.0.0->-r requirements.txt (line 4)) (6.1.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter>=1.0.0->-r requirements.txt (line 4)) (0.7.1)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter>=1.0.0->-r requirements.txt (line 4)) (0.4)\n",
            "Requirement already satisfied: jupyter-core>=4.7 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter>=1.0.0->-r requirements.txt (line 4)) (5.7.2)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter>=1.0.0->-r requirements.txt (line 4)) (0.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter>=1.0.0->-r requirements.txt (line 4)) (2.1.5)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter>=1.0.0->-r requirements.txt (line 4)) (0.8.4)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter>=1.0.0->-r requirements.txt (line 4)) (0.10.0)\n",
            "Requirement already satisfied: nbformat>=5.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter>=1.0.0->-r requirements.txt (line 4)) (5.10.3)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter>=1.0.0->-r requirements.txt (line 4)) (1.5.1)\n",
            "Requirement already satisfied: tinycss2 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter>=1.0.0->-r requirements.txt (line 4)) (1.2.1)\n",
            "Requirement already satisfied: pyzmq<25,>=17 in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter>=1.0.0->-r requirements.txt (line 4)) (23.2.1)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter>=1.0.0->-r requirements.txt (line 4)) (23.1.0)\n",
            "Requirement already satisfied: nest-asyncio>=1.5 in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter>=1.0.0->-r requirements.txt (line 4)) (1.6.0)\n",
            "Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter>=1.0.0->-r requirements.txt (line 4)) (1.8.2)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter>=1.0.0->-r requirements.txt (line 4)) (0.18.1)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter>=1.0.0->-r requirements.txt (line 4)) (0.20.0)\n",
            "Requirement already satisfied: nbclassic>=0.4.7 in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter>=1.0.0->-r requirements.txt (line 4)) (1.0.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=2.17.1->-r requirements.txt (line 5)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=2.17.1->-r requirements.txt (line 5)) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=2.17.1->-r requirements.txt (line 5)) (2024.1)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic->deepspeed==0.13.1->-r requirements.txt (line 8)) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic->deepspeed==0.13.1->-r requirements.txt (line 8)) (2.16.3)\n",
            "Requirement already satisfied: qtpy>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from qtconsole->jupyter>=1.0.0->-r requirements.txt (line 4)) (2.4.1)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->jupyter>=1.0.0->-r requirements.txt (line 4)) (67.7.2)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->jupyter>=1.0.0->-r requirements.txt (line 4)) (0.19.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->jupyter>=1.0.0->-r requirements.txt (line 4)) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->jupyter>=1.0.0->-r requirements.txt (line 4)) (0.7.5)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->jupyter>=1.0.0->-r requirements.txt (line 4)) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->jupyter>=1.0.0->-r requirements.txt (line 4)) (0.1.6)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->jupyter>=1.0.0->-r requirements.txt (line 4)) (4.9.0)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/dist-packages (from jupyter-core>=4.7->nbconvert->jupyter>=1.0.0->-r requirements.txt (line 4)) (4.2.0)\n",
            "Requirement already satisfied: jupyter-server>=1.8 in /usr/local/lib/python3.10/dist-packages (from nbclassic>=0.4.7->notebook->jupyter>=1.0.0->-r requirements.txt (line 4)) (1.24.0)\n",
            "Requirement already satisfied: notebook-shim>=0.2.3 in /usr/local/lib/python3.10/dist-packages (from nbclassic>=0.4.7->notebook->jupyter>=1.0.0->-r requirements.txt (line 4)) (0.2.4)\n",
            "Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.10/dist-packages (from nbformat>=5.1->nbconvert->jupyter>=1.0.0->-r requirements.txt (line 4)) (2.19.1)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.10/dist-packages (from nbformat>=5.1->nbconvert->jupyter>=1.0.0->-r requirements.txt (line 4)) (4.19.2)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->jupyter-console->jupyter>=1.0.0->-r requirements.txt (line 4)) (0.2.13)\n",
            "Requirement already satisfied: ptyprocess in /usr/local/lib/python3.10/dist-packages (from terminado>=0.8.3->notebook->jupyter>=1.0.0->-r requirements.txt (line 4)) (0.7.0)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.10/dist-packages (from argon2-cffi->notebook->jupyter>=1.0.0->-r requirements.txt (line 4)) (21.2.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->nbconvert->jupyter>=1.0.0->-r requirements.txt (line 4)) (2.5)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->nbconvert->jupyter>=1.0.0->-r requirements.txt (line 4)) (0.5.1)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->deepspeed==0.13.1->-r requirements.txt (line 8)) (1.3.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=5.0.0->ipykernel->jupyter>=1.0.0->-r requirements.txt (line 4)) (0.8.3)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=5.1->nbconvert->jupyter>=1.0.0->-r requirements.txt (line 4)) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=5.1->nbconvert->jupyter>=1.0.0->-r requirements.txt (line 4)) (0.34.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=5.1->nbconvert->jupyter>=1.0.0->-r requirements.txt (line 4)) (0.18.0)\n",
            "Requirement already satisfied: anyio<4,>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook->jupyter>=1.0.0->-r requirements.txt (line 4)) (3.7.1)\n",
            "Requirement already satisfied: websocket-client in /usr/local/lib/python3.10/dist-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook->jupyter>=1.0.0->-r requirements.txt (line 4)) (1.7.0)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from argon2-cffi-bindings->argon2-cffi->notebook->jupyter>=1.0.0->-r requirements.txt (line 4)) (1.16.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook->jupyter>=1.0.0->-r requirements.txt (line 4)) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook->jupyter>=1.0.0->-r requirements.txt (line 4)) (1.2.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook->jupyter>=1.0.0->-r requirements.txt (line 4)) (2.22)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoModel, AutoTokenizer, BitsAndBytesConfig\n",
        "\n",
        "# 模型ID或本地路径\n",
        "model_name_or_path = 'THUDM/chatglm3-6b'"
      ],
      "metadata": {
        "id": "GqPEa7GxgC5m"
      },
      "id": "GqPEa7GxgC5m",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# base_model = AutoModel.from_pretrained(model_name_or_path,\n",
        "#                                        device_map='auto',\n",
        "#                                        trust_remote_code=True)\n",
        "\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"THUDM/chatglm3-6b\", trust_remote_code=True)\n",
        "model = AutoModel.from_pretrained(\"THUDM/chatglm3-6b\", trust_remote_code=True).half().cuda()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233,
          "referenced_widgets": [
            "c7904fb138d54f6cba16bc3eaac4edee",
            "f6fcdb223eac4078a65625715e374f0d",
            "45e85fcdb3ad44109653cc25bc477536",
            "462d678630044a349ef0f3f1c57a1aeb",
            "ef36a91ad58b43a5ae5a474c12b4e058",
            "80350e8702404d2e9fbada30d410d203",
            "44fad327810c460381bc6b9e1129c2bf",
            "8398b08912ad4526b6b756c20b85764b",
            "7a2435fb8ea04811b1157e68c59f5be9",
            "1f6d64fbd9a1485fa256bc216cb043cb",
            "5b505a3461234fafb68c21cc003a0add"
          ]
        },
        "id": "tlM0onuMgL03",
        "outputId": "0a2e560c-00ae-4cf9-dad9-44953fd93201"
      },
      "id": "tlM0onuMgL03",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "WARNING:transformers_modules.THUDM.chatglm3-6b.a5ba5501eb873d40d48bd0983bd2a8dd006bb838.tokenization_chatglm:Setting eos_token is not supported, use the default one.\n",
            "WARNING:transformers_modules.THUDM.chatglm3-6b.a5ba5501eb873d40d48bd0983bd2a8dd006bb838.tokenization_chatglm:Setting pad_token is not supported, use the default one.\n",
            "WARNING:transformers_modules.THUDM.chatglm3-6b.a5ba5501eb873d40d48bd0983bd2a8dd006bb838.tokenization_chatglm:Setting unk_token is not supported, use the default one.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/7 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c7904fb138d54f6cba16bc3eaac4edee"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output_dir = f\"models/{model_name_or_path}\"\n",
        "\n",
        "model.save_pretrained(output_dir)\n",
        "tokenizer.save_pretrained(output_dir)\n",
        "# model = model.eval()\n",
        "\n",
        "# response, history = model.chat(tokenizer, \"你好\", history=[])\n",
        "\n",
        "# print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ztlMtf9xiSS0",
        "outputId": "a8ac10b3-291e-4665-9602-58edebe2afd1"
      },
      "id": "ztlMtf9xiSS0",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('models/THUDM/chatglm3-6b/tokenizer_config.json',\n",
              " 'models/THUDM/chatglm3-6b/special_tokens_map.json',\n",
              " 'models/THUDM/chatglm3-6b/tokenizer.model',\n",
              " 'models/THUDM/chatglm3-6b/added_tokens.json')"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "import json\n",
        "from typing import Union\n",
        "from pathlib import Path\n",
        "\n",
        "\n",
        "def _resolve_path(path: Union[str, Path]) -> Path:\n",
        "    return Path(path).expanduser().resolve()\n",
        "\n",
        "\n",
        "def _mkdir(dir_name: Union[str, Path]):\n",
        "    dir_name = _resolve_path(dir_name)\n",
        "    if not dir_name.is_dir():\n",
        "        dir_name.mkdir(parents=True, exist_ok=False)\n",
        "\n",
        "\n",
        "def convert_adgen(data_dir: Union[str, Path], save_dir: Union[str, Path]):\n",
        "    def _convert(in_file: Path, out_file: Path):\n",
        "        _mkdir(out_file.parent)\n",
        "        with open(in_file, encoding='utf-8') as fin:\n",
        "            with open(out_file, 'wt', encoding='utf-8') as fout:\n",
        "                for line in fin:\n",
        "                    dct = json.loads(line)\n",
        "                    sample = {'conversations': [{'role': 'user', 'content': dct['content']},\n",
        "                                                {'role': 'assistant', 'content': dct['summary']}]}\n",
        "                    fout.write(json.dumps(sample, ensure_ascii=False) + '\\n')\n",
        "\n",
        "    data_dir = _resolve_path(data_dir)\n",
        "    save_dir = _resolve_path(save_dir)\n",
        "\n",
        "    train_file = data_dir / 'train.json'\n",
        "    if train_file.is_file():\n",
        "        out_file = save_dir / train_file.relative_to(data_dir)\n",
        "        _convert(train_file, out_file)\n",
        "\n",
        "    dev_file = data_dir / 'dev.json'\n",
        "    if dev_file.is_file():\n",
        "        out_file = save_dir / dev_file.relative_to(data_dir)\n",
        "        _convert(dev_file, out_file)\n",
        "\n",
        "\n",
        "convert_adgen('/content/drive/MyDrive/data/finetune_demo/AdvertiseGen', '/content/drive/MyDrive/data/finetune_demo/AdvertiseGen_fix')"
      ],
      "metadata": {
        "collapsed": true,
        "ExecuteTime": {
          "end_time": "2024-01-18T05:02:34.749308Z",
          "start_time": "2024-01-18T05:02:25.564458Z"
        },
        "id": "initial_id"
      },
      "id": "initial_id"
    },
    {
      "cell_type": "code",
      "source": [
        "import locale\n",
        "locale.getpreferredencoding = lambda: \"UTF-8\""
      ],
      "metadata": {
        "id": "yjm4y4MromNi"
      },
      "id": "yjm4y4MromNi",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. 使用命令行开始微调,我们使用 lora 进行微调\n",
        "接着，我们仅需要将配置好的参数以命令行的形式传参给程序，就可以使用命令行进行高效微调，这里将 `/media/zr/Data/Code/ChatGLM3/venv/bin/python3` 换成你的 python3 的绝对路径以保证正常运行。"
      ],
      "metadata": {
        "collapsed": false,
        "id": "a1b7a99923349056"
      },
      "id": "a1b7a99923349056"
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-04-04 00:12:32.395749: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-04-04 00:12:32.395804: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-04-04 00:12:32.397587: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-04-04 00:12:33.472625: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Setting eos_token is not supported, use the default one.\n",
            "Setting pad_token is not supported, use the default one.\n",
            "Setting unk_token is not supported, use the default one.\n",
            "Loading checkpoint shards: 100% 3/3 [00:03<00:00,  1.12s/it]\n",
            "trainable params: 974,848 || all params: 6,244,558,848 || trainable%: 0.01561115883009451\n",
            "--> Model\n",
            "\n",
            "--> model has 0.974848M params\n",
            "\n",
            "Setting num_proc from 16 back to 1 for the train split to disable multiprocessing as it only contains one shard.\n",
            "Generating train split: 114599 examples [00:00, 540986.87 examples/s]\n",
            "Setting num_proc from 16 back to 1 for the validation split to disable multiprocessing as it only contains one shard.\n",
            "Generating validation split: 1070 examples [00:00, 162935.86 examples/s]\n",
            "Setting num_proc from 16 back to 1 for the test split to disable multiprocessing as it only contains one shard.\n",
            "Generating test split: 1070 examples [00:00, 197531.04 examples/s]\n",
            "Map (num_proc=16): 100% 114599/114599 [00:04<00:00, 26810.30 examples/s]\n",
            "train_dataset: Dataset({\n",
            "    features: ['input_ids', 'labels'],\n",
            "    num_rows: 114599\n",
            "})\n",
            "Map (num_proc=16): 100% 1070/1070 [00:00<00:00, 1625.01 examples/s]\n",
            "val_dataset: Dataset({\n",
            "    features: ['input_ids', 'output_ids'],\n",
            "    num_rows: 1070\n",
            "})\n",
            "Map (num_proc=16): 100% 1070/1070 [00:00<00:00, 1635.84 examples/s]\n",
            "test_dataset: Dataset({\n",
            "    features: ['input_ids', 'output_ids'],\n",
            "    num_rows: 1070\n",
            "})\n",
            "--> Sanity check\n",
            "           '[gMASK]': 64790 -> -100\n",
            "               'sop': 64792 -> -100\n",
            "          '<|user|>': 64795 -> -100\n",
            "                  '': 30910 -> -100\n",
            "                '\\n': 13 -> -100\n",
            "                  '': 30910 -> -100\n",
            "                '类型': 33467 -> -100\n",
            "                 '#': 31010 -> -100\n",
            "                 '裤': 56532 -> -100\n",
            "                 '*': 30998 -> -100\n",
            "                 '版': 55090 -> -100\n",
            "                 '型': 54888 -> -100\n",
            "                 '#': 31010 -> -100\n",
            "                '宽松': 40833 -> -100\n",
            "                 '*': 30998 -> -100\n",
            "                '风格': 32799 -> -100\n",
            "                 '#': 31010 -> -100\n",
            "                '性感': 40589 -> -100\n",
            "                 '*': 30998 -> -100\n",
            "                '图案': 37505 -> -100\n",
            "                 '#': 31010 -> -100\n",
            "                '线条': 37216 -> -100\n",
            "                 '*': 30998 -> -100\n",
            "                 '裤': 56532 -> -100\n",
            "                 '型': 54888 -> -100\n",
            "                 '#': 31010 -> -100\n",
            "                 '阔': 56529 -> -100\n",
            "                 '腿': 56158 -> -100\n",
            "                 '裤': 56532 -> -100\n",
            "     '<|assistant|>': 64796 -> -100\n",
            "                  '': 30910 -> 30910\n",
            "                '\\n': 13 -> 13\n",
            "                  '': 30910 -> 30910\n",
            "                '宽松': 40833 -> 40833\n",
            "                 '的': 54530 -> 54530\n",
            "                 '阔': 56529 -> 56529\n",
            "                 '腿': 56158 -> 56158\n",
            "                 '裤': 56532 -> 56532\n",
            "                 '这': 54551 -> 54551\n",
            "                '两年': 33808 -> 33808\n",
            "                '真的': 32041 -> 32041\n",
            "                 '吸': 55360 -> 55360\n",
            "                 '粉': 55486 -> 55486\n",
            "                '不少': 32138 -> 32138\n",
            "                 '，': 31123 -> 31123\n",
            "                '明星': 32943 -> 32943\n",
            "                '时尚': 33481 -> 33481\n",
            "                 '达': 54880 -> 54880\n",
            "                '人的': 31664 -> 31664\n",
            "                '心头': 46565 -> 46565\n",
            "                 '爱': 54799 -> 54799\n",
            "                 '。': 31155 -> 31155\n",
            "                '毕竟': 33051 -> 33051\n",
            "                 '好': 54591 -> 54591\n",
            "                 '穿': 55432 -> 55432\n",
            "                '时尚': 33481 -> 33481\n",
            "                 '，': 31123 -> 31123\n",
            "                 '谁': 55622 -> 55622\n",
            "                '都能': 32904 -> 32904\n",
            "                 '穿': 55432 -> 55432\n",
            "                 '出': 54557 -> 54557\n",
            "                 '腿': 56158 -> 56158\n",
            "                 '长': 54625 -> 54625\n",
            "                 '2': 30943 -> 30943\n",
            "                 '米': 55055 -> 55055\n",
            "               '的效果': 35590 -> 35590\n",
            "                '宽松': 40833 -> 40833\n",
            "                 '的': 54530 -> 54530\n",
            "                 '裤': 56532 -> 56532\n",
            "                 '腿': 56158 -> 56158\n",
            "                 '，': 31123 -> 31123\n",
            "               '当然是': 48466 -> 48466\n",
            "                 '遮': 57148 -> 57148\n",
            "                 '肉': 55343 -> 55343\n",
            "                 '小': 54603 -> 54603\n",
            "                '能手': 49355 -> 49355\n",
            "                 '啊': 55674 -> 55674\n",
            "                 '。': 31155 -> 31155\n",
            "                '上身': 51605 -> 51605\n",
            "                 '随': 55119 -> 55119\n",
            "                 '性': 54642 -> 54642\n",
            "                '自然': 31799 -> 31799\n",
            "                 '不': 54535 -> 54535\n",
            "                 '拘': 57036 -> 57036\n",
            "                 '束': 55625 -> 55625\n",
            "                 '，': 31123 -> 31123\n",
            "                '面料': 46839 -> 46839\n",
            "                 '亲': 55113 -> 55113\n",
            "                 '肤': 56089 -> 56089\n",
            "                '舒适': 33894 -> 33894\n",
            "                 '贴': 55778 -> 55778\n",
            "                '身体': 31902 -> 31902\n",
            "                 '验': 55017 -> 55017\n",
            "                 '感': 54706 -> 54706\n",
            "                 '棒': 56382 -> 56382\n",
            "                 '棒': 56382 -> 56382\n",
            "                 '哒': 59230 -> 59230\n",
            "                 '。': 31155 -> 31155\n",
            "                 '系': 54712 -> 54712\n",
            "                 '带': 54882 -> 54882\n",
            "                '部分': 31726 -> 31726\n",
            "                '增加': 31917 -> 31917\n",
            "                '设计': 31735 -> 31735\n",
            "                '看点': 45032 -> 45032\n",
            "                 '，': 31123 -> 31123\n",
            "                 '还': 54656 -> 54656\n",
            "                 '让': 54772 -> 54772\n",
            "                '单品': 46539 -> 46539\n",
            "               '的设计': 34481 -> 34481\n",
            "                 '感': 54706 -> 54706\n",
            "                '更强': 43084 -> 43084\n",
            "                 '。': 31155 -> 31155\n",
            "                '腿部': 46799 -> 46799\n",
            "                '线条': 37216 -> 37216\n",
            "                 '若': 55351 -> 55351\n",
            "                 '隐': 55733 -> 55733\n",
            "                 '若': 55351 -> 55351\n",
            "                 '现': 54600 -> 54600\n",
            "                 '的': 54530 -> 54530\n",
            "                 '，': 31123 -> 31123\n",
            "                '性感': 40589 -> 40589\n",
            "                 '撩': 58521 -> 58521\n",
            "                 '人': 54533 -> 54533\n",
            "                 '。': 31155 -> 31155\n",
            "                '颜色': 33692 -> 33692\n",
            "                 '敲': 57004 -> 57004\n",
            "                '温柔': 34678 -> 34678\n",
            "                 '的': 54530 -> 54530\n",
            "                 '，': 31123 -> 31123\n",
            "                 '与': 54619 -> 54619\n",
            "                '裤子': 44722 -> 44722\n",
            "                '本身': 32754 -> 32754\n",
            "                 '所': 54626 -> 54626\n",
            "                '呈现': 33169 -> 33169\n",
            "               '的风格': 48084 -> 48084\n",
            "                '有点': 33149 -> 33149\n",
            "                 '反': 54955 -> 54955\n",
            "                 '差': 55342 -> 55342\n",
            "                 '萌': 56842 -> 56842\n",
            "                 '。': 31155 -> 31155\n",
            "                  '': 2 -> 2\n",
            "/usr/local/lib/python3.10/dist-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
            "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
            "  warnings.warn(\n",
            "max_steps is given, it will override any value given in num_train_epochs\n",
            "Using auto half precision backend\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "***** Running training *****\n",
            "  Num examples = 114,599\n",
            "  Num Epochs = 2\n",
            "  Instantaneous batch size per device = 4\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
            "  Gradient Accumulation steps = 4\n",
            "  Total optimization steps = 8,000\n",
            "  Number of trainable parameters = 974,848\n",
            "{'loss': 4.4769, 'grad_norm': 4.457520484924316, 'learning_rate': 4.984375e-05, 'epoch': 0.0}\n",
            "{'loss': 3.8729, 'grad_norm': 3.1617679595947266, 'learning_rate': 4.96875e-05, 'epoch': 0.01}\n",
            "{'loss': 3.6489, 'grad_norm': 3.3320322036743164, 'learning_rate': 4.953125e-05, 'epoch': 0.01}\n",
            "{'loss': 3.5044, 'grad_norm': 4.019688129425049, 'learning_rate': 4.937500000000001e-05, 'epoch': 0.01}\n",
            "{'loss': 3.4787, 'grad_norm': 4.111749649047852, 'learning_rate': 4.921875e-05, 'epoch': 0.02}\n",
            "{'loss': 3.4398, 'grad_norm': 4.5902934074401855, 'learning_rate': 4.90625e-05, 'epoch': 0.02}\n",
            "{'loss': 3.3881, 'grad_norm': 4.6386237144470215, 'learning_rate': 4.8906250000000006e-05, 'epoch': 0.02}\n",
            "{'loss': 3.4003, 'grad_norm': 4.84608268737793, 'learning_rate': 4.875e-05, 'epoch': 0.03}\n",
            "{'loss': 3.3342, 'grad_norm': 5.218606948852539, 'learning_rate': 4.8593750000000005e-05, 'epoch': 0.03}\n",
            "{'loss': 3.3622, 'grad_norm': 5.158422470092773, 'learning_rate': 4.8437500000000005e-05, 'epoch': 0.03}\n",
            "{'loss': 3.3701, 'grad_norm': 5.2556867599487305, 'learning_rate': 4.828125e-05, 'epoch': 0.04}\n",
            "{'loss': 3.3174, 'grad_norm': 5.343079090118408, 'learning_rate': 4.8125000000000004e-05, 'epoch': 0.04}\n",
            "{'loss': 3.2815, 'grad_norm': 5.956881999969482, 'learning_rate': 4.7968750000000004e-05, 'epoch': 0.05}\n",
            "{'loss': 3.3043, 'grad_norm': 5.705592632293701, 'learning_rate': 4.7812500000000003e-05, 'epoch': 0.05}\n",
            "{'loss': 3.27, 'grad_norm': 5.913350582122803, 'learning_rate': 4.765625e-05, 'epoch': 0.05}\n",
            "{'loss': 3.3241, 'grad_norm': 5.243463516235352, 'learning_rate': 4.75e-05, 'epoch': 0.06}\n",
            "{'loss': 3.2906, 'grad_norm': 5.332241058349609, 'learning_rate': 4.734375e-05, 'epoch': 0.06}\n",
            "{'loss': 3.3128, 'grad_norm': 5.840092182159424, 'learning_rate': 4.71875e-05, 'epoch': 0.06}\n",
            "{'loss': 3.2887, 'grad_norm': 6.837751865386963, 'learning_rate': 4.703125e-05, 'epoch': 0.07}\n",
            "{'loss': 3.2726, 'grad_norm': 6.142899036407471, 'learning_rate': 4.6875e-05, 'epoch': 0.07}\n",
            "{'loss': 3.3246, 'grad_norm': 6.313248634338379, 'learning_rate': 4.671875e-05, 'epoch': 0.07}\n",
            "{'loss': 3.2888, 'grad_norm': 6.160290718078613, 'learning_rate': 4.65625e-05, 'epoch': 0.08}\n",
            "{'loss': 3.2673, 'grad_norm': 6.094671249389648, 'learning_rate': 4.640625e-05, 'epoch': 0.08}\n",
            "{'loss': 3.2477, 'grad_norm': 5.925835132598877, 'learning_rate': 4.6250000000000006e-05, 'epoch': 0.08}\n",
            "{'loss': 3.2487, 'grad_norm': 6.062042713165283, 'learning_rate': 4.609375e-05, 'epoch': 0.09}\n",
            "{'loss': 3.2738, 'grad_norm': 6.096379280090332, 'learning_rate': 4.59375e-05, 'epoch': 0.09}\n",
            "{'loss': 3.3022, 'grad_norm': 6.839846134185791, 'learning_rate': 4.5781250000000005e-05, 'epoch': 0.09}\n",
            "{'loss': 3.228, 'grad_norm': 6.791756629943848, 'learning_rate': 4.5625e-05, 'epoch': 0.1}\n",
            "{'loss': 3.2706, 'grad_norm': 6.396697044372559, 'learning_rate': 4.5468750000000004e-05, 'epoch': 0.1}\n",
            "{'loss': 3.2283, 'grad_norm': 6.21622896194458, 'learning_rate': 4.5312500000000004e-05, 'epoch': 0.1}\n",
            "{'loss': 3.2379, 'grad_norm': 6.2512431144714355, 'learning_rate': 4.515625e-05, 'epoch': 0.11}\n",
            "{'loss': 3.2528, 'grad_norm': 6.121426582336426, 'learning_rate': 4.5e-05, 'epoch': 0.11}\n",
            "{'loss': 3.2513, 'grad_norm': 6.805795669555664, 'learning_rate': 4.484375e-05, 'epoch': 0.12}\n",
            "{'loss': 3.2243, 'grad_norm': 6.376026630401611, 'learning_rate': 4.46875e-05, 'epoch': 0.12}\n",
            "{'loss': 3.2006, 'grad_norm': 6.409020900726318, 'learning_rate': 4.453125e-05, 'epoch': 0.12}\n",
            "{'loss': 3.1895, 'grad_norm': 6.432254314422607, 'learning_rate': 4.4375e-05, 'epoch': 0.13}\n",
            "{'loss': 3.2205, 'grad_norm': 6.639708042144775, 'learning_rate': 4.421875e-05, 'epoch': 0.13}\n",
            "{'loss': 3.1868, 'grad_norm': 6.560477256774902, 'learning_rate': 4.40625e-05, 'epoch': 0.13}\n",
            "{'loss': 3.2481, 'grad_norm': 6.305062294006348, 'learning_rate': 4.390625000000001e-05, 'epoch': 0.14}\n",
            "{'loss': 3.2503, 'grad_norm': 6.576470375061035, 'learning_rate': 4.375e-05, 'epoch': 0.14}\n",
            " 12% 1000/8000 [13:14<1:31:10,  1.28it/s]***** Running Evaluation *****\n",
            "  Num examples = 50\n",
            "  Batch size = 16\n",
            "\n",
            "  0% 0/4 [00:00<?, ?it/s]\u001b[A\n",
            " 50% 2/4 [00:04<00:04,  2.12s/it]\u001b[A\n",
            " 75% 3/4 [00:14<00:05,  5.63s/it]\u001b[A\n",
            "100% 4/4 [00:25<00:00,  7.51s/it]\u001b[ABuilding prefix dict from the default dictionary ...\n",
            "Loading model from cache /tmp/jieba.cache\n",
            "Loading model cost 0.689 seconds.\n",
            "Prefix dict has been built successfully.\n",
            "                                         \n",
            "\u001b[A{'eval_rouge-1': 32.165838, 'eval_rouge-2': 7.564022000000001, 'eval_rouge-l': 25.218594, 'eval_bleu-4': 0.03522149914230722, 'eval_runtime': 30.4194, 'eval_samples_per_second': 1.644, 'eval_steps_per_second': 0.131, 'epoch': 0.14}\n",
            " 12% 1000/8000 [13:45<1:31:10,  1.28it/s]\n",
            "100% 4/4 [00:26<00:00,  7.51s/it]\u001b[A\n",
            "                                 \u001b[ACheckpoint destination directory ./output/checkpoint-1000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Saving model checkpoint to ./output/checkpoint-1000\n",
            "/usr/local/lib/python3.10/dist-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in models/THUDM/chatglm3-6b - will assume that the vocabulary was not modified.\n",
            "  warnings.warn(\n",
            "{'loss': 3.2115, 'grad_norm': 6.4509687423706055, 'learning_rate': 4.359375e-05, 'epoch': 0.14}\n",
            "{'loss': 3.2273, 'grad_norm': 6.4296674728393555, 'learning_rate': 4.3437500000000006e-05, 'epoch': 0.15}\n",
            "{'loss': 3.2113, 'grad_norm': 6.9615278244018555, 'learning_rate': 4.328125e-05, 'epoch': 0.15}\n",
            "{'loss': 3.1839, 'grad_norm': 6.54206657409668, 'learning_rate': 4.3125000000000005e-05, 'epoch': 0.15}\n",
            "{'loss': 3.2053, 'grad_norm': 6.394674301147461, 'learning_rate': 4.2968750000000004e-05, 'epoch': 0.16}\n",
            "{'loss': 3.1956, 'grad_norm': 7.210118770599365, 'learning_rate': 4.28125e-05, 'epoch': 0.16}\n",
            "{'loss': 3.2524, 'grad_norm': 6.8298659324646, 'learning_rate': 4.2656250000000003e-05, 'epoch': 0.16}\n",
            "{'loss': 3.2311, 'grad_norm': 6.294135570526123, 'learning_rate': 4.25e-05, 'epoch': 0.17}\n",
            "{'loss': 3.1903, 'grad_norm': 6.0237298011779785, 'learning_rate': 4.234375e-05, 'epoch': 0.17}\n",
            "{'loss': 3.1671, 'grad_norm': 6.09128475189209, 'learning_rate': 4.21875e-05, 'epoch': 0.17}\n",
            "{'loss': 3.2198, 'grad_norm': 6.46207857131958, 'learning_rate': 4.203125e-05, 'epoch': 0.18}\n",
            "{'loss': 3.1934, 'grad_norm': 6.753966331481934, 'learning_rate': 4.1875e-05, 'epoch': 0.18}\n",
            "{'loss': 3.1442, 'grad_norm': 6.480440616607666, 'learning_rate': 4.171875e-05, 'epoch': 0.18}\n",
            "{'loss': 3.1612, 'grad_norm': 6.477458953857422, 'learning_rate': 4.156250000000001e-05, 'epoch': 0.19}\n",
            "{'loss': 3.1853, 'grad_norm': 6.5325493812561035, 'learning_rate': 4.140625e-05, 'epoch': 0.19}\n",
            "{'loss': 3.1986, 'grad_norm': 6.333869457244873, 'learning_rate': 4.125e-05, 'epoch': 0.2}\n",
            "{'loss': 3.2043, 'grad_norm': 6.496013164520264, 'learning_rate': 4.1093750000000006e-05, 'epoch': 0.2}\n",
            "{'loss': 3.2212, 'grad_norm': 6.516563892364502, 'learning_rate': 4.09375e-05, 'epoch': 0.2}\n",
            "{'loss': 3.1183, 'grad_norm': 5.9534807205200195, 'learning_rate': 4.0781250000000005e-05, 'epoch': 0.21}\n",
            "{'loss': 3.2643, 'grad_norm': 6.22523307800293, 'learning_rate': 4.0625000000000005e-05, 'epoch': 0.21}\n",
            "{'loss': 3.162, 'grad_norm': 6.4839301109313965, 'learning_rate': 4.046875e-05, 'epoch': 0.21}\n",
            "{'loss': 3.1716, 'grad_norm': 6.805156707763672, 'learning_rate': 4.0312500000000004e-05, 'epoch': 0.22}\n",
            "{'loss': 3.1698, 'grad_norm': 6.619258403778076, 'learning_rate': 4.0156250000000004e-05, 'epoch': 0.22}\n",
            "{'loss': 3.2452, 'grad_norm': 6.27993631362915, 'learning_rate': 4e-05, 'epoch': 0.22}\n",
            "{'loss': 3.2067, 'grad_norm': 6.301827907562256, 'learning_rate': 3.984375e-05, 'epoch': 0.23}\n",
            "{'loss': 3.1944, 'grad_norm': 6.387763500213623, 'learning_rate': 3.96875e-05, 'epoch': 0.23}\n",
            "{'loss': 3.1461, 'grad_norm': 6.992061138153076, 'learning_rate': 3.953125e-05, 'epoch': 0.23}\n",
            "{'loss': 3.1806, 'grad_norm': 6.26113224029541, 'learning_rate': 3.9375e-05, 'epoch': 0.24}\n",
            "{'loss': 3.1856, 'grad_norm': 6.756810665130615, 'learning_rate': 3.921875e-05, 'epoch': 0.24}\n",
            "{'loss': 3.1715, 'grad_norm': 6.1924052238464355, 'learning_rate': 3.90625e-05, 'epoch': 0.24}\n",
            "{'loss': 3.1827, 'grad_norm': 7.058562278747559, 'learning_rate': 3.890625e-05, 'epoch': 0.25}\n",
            "{'loss': 3.1903, 'grad_norm': 6.84136962890625, 'learning_rate': 3.875e-05, 'epoch': 0.25}\n",
            "{'loss': 3.1493, 'grad_norm': 6.538081169128418, 'learning_rate': 3.859375e-05, 'epoch': 0.25}\n",
            "{'loss': 3.154, 'grad_norm': 7.072056770324707, 'learning_rate': 3.8437500000000006e-05, 'epoch': 0.26}\n",
            "{'loss': 3.1334, 'grad_norm': 6.82246208190918, 'learning_rate': 3.828125e-05, 'epoch': 0.26}\n",
            "{'loss': 3.2051, 'grad_norm': 6.305246353149414, 'learning_rate': 3.8125e-05, 'epoch': 0.27}\n",
            "{'loss': 3.1475, 'grad_norm': 6.560094356536865, 'learning_rate': 3.7968750000000005e-05, 'epoch': 0.27}\n",
            "{'loss': 3.1673, 'grad_norm': 6.112670421600342, 'learning_rate': 3.78125e-05, 'epoch': 0.27}\n",
            "{'loss': 3.1757, 'grad_norm': 6.690279006958008, 'learning_rate': 3.7656250000000004e-05, 'epoch': 0.28}\n",
            "{'loss': 3.1618, 'grad_norm': 6.66140079498291, 'learning_rate': 3.7500000000000003e-05, 'epoch': 0.28}\n",
            " 25% 2000/8000 [27:00<1:17:26,  1.29it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 50\n",
            "  Batch size = 16\n",
            "\n",
            "  0% 0/4 [00:00<?, ?it/s]\u001b[A\n",
            " 50% 2/4 [00:06<00:06,  3.20s/it]\u001b[A\n",
            " 75% 3/4 [00:09<00:03,  3.15s/it]\u001b[A\n",
            "                                         \n",
            "\u001b[A{'eval_rouge-1': 33.10444, 'eval_rouge-2': 7.349438, 'eval_rouge-l': 26.300659999999997, 'eval_bleu-4': 0.03414869415590823, 'eval_runtime': 16.8042, 'eval_samples_per_second': 2.975, 'eval_steps_per_second': 0.238, 'epoch': 0.28}\n",
            " 25% 2000/8000 [27:17<1:17:26,  1.29it/s]\n",
            "100% 4/4 [00:12<00:00,  3.18s/it]\u001b[A\n",
            "                                 \u001b[ACheckpoint destination directory ./output/checkpoint-2000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Saving model checkpoint to ./output/checkpoint-2000\n",
            "/usr/local/lib/python3.10/dist-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in models/THUDM/chatglm3-6b - will assume that the vocabulary was not modified.\n",
            "  warnings.warn(\n",
            "{'loss': 3.1326, 'grad_norm': 6.674555778503418, 'learning_rate': 3.7343749999999996e-05, 'epoch': 0.28}\n",
            "{'loss': 3.1839, 'grad_norm': 7.307922840118408, 'learning_rate': 3.71875e-05, 'epoch': 0.29}\n",
            "{'loss': 3.1638, 'grad_norm': 6.617319583892822, 'learning_rate': 3.703125e-05, 'epoch': 0.29}\n",
            "{'loss': 3.1436, 'grad_norm': 6.738682746887207, 'learning_rate': 3.6875e-05, 'epoch': 0.29}\n",
            "{'loss': 3.1376, 'grad_norm': 6.078250885009766, 'learning_rate': 3.6725000000000005e-05, 'epoch': 0.3}\n",
            "{'loss': 3.1484, 'grad_norm': 6.714727401733398, 'learning_rate': 3.6568750000000005e-05, 'epoch': 0.3}\n",
            "{'loss': 3.1794, 'grad_norm': 6.268121242523193, 'learning_rate': 3.64125e-05, 'epoch': 0.3}\n",
            "{'loss': 3.1473, 'grad_norm': 6.742485046386719, 'learning_rate': 3.6256250000000004e-05, 'epoch': 0.31}\n",
            "{'loss': 3.1608, 'grad_norm': 6.927061080932617, 'learning_rate': 3.61e-05, 'epoch': 0.31}\n",
            "{'loss': 3.1755, 'grad_norm': 6.897130012512207, 'learning_rate': 3.594375e-05, 'epoch': 0.31}\n",
            "{'loss': 3.1453, 'grad_norm': 6.757779121398926, 'learning_rate': 3.57875e-05, 'epoch': 0.32}\n",
            "{'loss': 3.1178, 'grad_norm': 6.50203275680542, 'learning_rate': 3.563125e-05, 'epoch': 0.32}\n",
            "{'loss': 3.1496, 'grad_norm': 6.481674671173096, 'learning_rate': 3.5475e-05, 'epoch': 0.32}\n",
            "{'loss': 3.1502, 'grad_norm': 6.950092792510986, 'learning_rate': 3.531875e-05, 'epoch': 0.33}\n",
            "{'loss': 3.0898, 'grad_norm': 6.254732608795166, 'learning_rate': 3.51625e-05, 'epoch': 0.33}\n",
            "{'loss': 3.1618, 'grad_norm': 6.602299213409424, 'learning_rate': 3.500625e-05, 'epoch': 0.34}\n",
            "{'loss': 3.1617, 'grad_norm': 6.972589015960693, 'learning_rate': 3.485e-05, 'epoch': 0.34}\n",
            "{'loss': 3.1824, 'grad_norm': 6.65015983581543, 'learning_rate': 3.469375e-05, 'epoch': 0.34}\n",
            "{'loss': 3.0951, 'grad_norm': 6.812234401702881, 'learning_rate': 3.45375e-05, 'epoch': 0.35}\n",
            "{'loss': 3.1376, 'grad_norm': 6.558523178100586, 'learning_rate': 3.4381250000000006e-05, 'epoch': 0.35}\n",
            "{'loss': 3.1403, 'grad_norm': 7.078360080718994, 'learning_rate': 3.4225e-05, 'epoch': 0.35}\n",
            "{'loss': 3.15, 'grad_norm': 6.579682350158691, 'learning_rate': 3.406875e-05, 'epoch': 0.36}\n",
            "{'loss': 3.1494, 'grad_norm': 6.408431053161621, 'learning_rate': 3.3912500000000004e-05, 'epoch': 0.36}\n",
            "{'loss': 3.1361, 'grad_norm': 6.564065933227539, 'learning_rate': 3.375625e-05, 'epoch': 0.36}\n",
            "{'loss': 3.1411, 'grad_norm': 6.545934677124023, 'learning_rate': 3.3600000000000004e-05, 'epoch': 0.37}\n",
            "{'loss': 3.1167, 'grad_norm': 6.664008617401123, 'learning_rate': 3.344375e-05, 'epoch': 0.37}\n",
            "{'loss': 3.1244, 'grad_norm': 6.774341583251953, 'learning_rate': 3.3287499999999996e-05, 'epoch': 0.37}\n",
            "{'loss': 3.1264, 'grad_norm': 6.426333427429199, 'learning_rate': 3.313125e-05, 'epoch': 0.38}\n",
            "{'loss': 3.141, 'grad_norm': 6.810548305511475, 'learning_rate': 3.2975e-05, 'epoch': 0.38}\n",
            "{'loss': 3.0835, 'grad_norm': 6.6482648849487305, 'learning_rate': 3.281875e-05, 'epoch': 0.38}\n",
            "{'loss': 3.1329, 'grad_norm': 7.3148064613342285, 'learning_rate': 3.26625e-05, 'epoch': 0.39}\n",
            "{'loss': 3.1019, 'grad_norm': 6.424184799194336, 'learning_rate': 3.250625e-05, 'epoch': 0.39}\n",
            "{'loss': 3.1349, 'grad_norm': 6.7554612159729, 'learning_rate': 3.235e-05, 'epoch': 0.39}\n",
            "{'loss': 3.1216, 'grad_norm': 6.6205549240112305, 'learning_rate': 3.219375e-05, 'epoch': 0.4}\n",
            "{'loss': 3.1012, 'grad_norm': 6.617169380187988, 'learning_rate': 3.2037500000000006e-05, 'epoch': 0.4}\n",
            "{'loss': 3.1854, 'grad_norm': 6.610563278198242, 'learning_rate': 3.188125e-05, 'epoch': 0.4}\n",
            "{'loss': 3.0908, 'grad_norm': 6.676445960998535, 'learning_rate': 3.1725e-05, 'epoch': 0.41}\n",
            "{'loss': 3.1298, 'grad_norm': 6.773097515106201, 'learning_rate': 3.1568750000000005e-05, 'epoch': 0.41}\n",
            "{'loss': 3.0916, 'grad_norm': 7.008196830749512, 'learning_rate': 3.14125e-05, 'epoch': 0.42}\n",
            "{'loss': 3.0897, 'grad_norm': 6.7261433601379395, 'learning_rate': 3.1256250000000004e-05, 'epoch': 0.42}\n",
            " 38% 3000/8000 [40:30<1:06:30,  1.25it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 50\n",
            "  Batch size = 16\n",
            "\n",
            "  0% 0/4 [00:00<?, ?it/s]\u001b[A\n",
            " 50% 2/4 [00:10<00:10,  5.38s/it]\u001b[A\n",
            " 75% 3/4 [00:14<00:04,  4.49s/it]\u001b[A\n",
            "                                         \n",
            "\u001b[A{'eval_rouge-1': 33.708926, 'eval_rouge-2': 9.049389999999999, 'eval_rouge-l': 26.254508, 'eval_bleu-4': 0.043014276596233934, 'eval_runtime': 28.3729, 'eval_samples_per_second': 1.762, 'eval_steps_per_second': 0.141, 'epoch': 0.42}\n",
            " 38% 3000/8000 [40:58<1:06:30,  1.25it/s]\n",
            "100% 4/4 [00:17<00:00,  3.86s/it]\u001b[A\n",
            "                                 \u001b[ACheckpoint destination directory ./output/checkpoint-3000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
            "Saving model checkpoint to ./output/checkpoint-3000\n",
            "/usr/local/lib/python3.10/dist-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in models/THUDM/chatglm3-6b - will assume that the vocabulary was not modified.\n",
            "  warnings.warn(\n",
            "{'loss': 3.098, 'grad_norm': 6.563082695007324, 'learning_rate': 3.1100000000000004e-05, 'epoch': 0.42}\n",
            "{'loss': 3.0794, 'grad_norm': 6.825554847717285, 'learning_rate': 3.0943749999999997e-05, 'epoch': 0.43}\n",
            "{'loss': 3.1134, 'grad_norm': 6.428257465362549, 'learning_rate': 3.07875e-05, 'epoch': 0.43}\n",
            "{'loss': 3.1031, 'grad_norm': 6.6427388191223145, 'learning_rate': 3.063125e-05, 'epoch': 0.43}\n",
            "{'loss': 3.13, 'grad_norm': 6.998889923095703, 'learning_rate': 3.0475000000000002e-05, 'epoch': 0.44}\n",
            "{'loss': 3.1036, 'grad_norm': 6.975096225738525, 'learning_rate': 3.0318750000000002e-05, 'epoch': 0.44}\n",
            "{'loss': 3.1047, 'grad_norm': 6.853231906890869, 'learning_rate': 3.0162499999999998e-05, 'epoch': 0.44}\n",
            "{'loss': 3.0995, 'grad_norm': 7.169567584991455, 'learning_rate': 3.000625e-05, 'epoch': 0.45}\n",
            "{'loss': 3.0891, 'grad_norm': 7.225650787353516, 'learning_rate': 2.985e-05, 'epoch': 0.45}\n",
            "{'loss': 3.0778, 'grad_norm': 6.536144733428955, 'learning_rate': 2.9693750000000003e-05, 'epoch': 0.45}\n",
            "{'loss': 3.0905, 'grad_norm': 6.7784857749938965, 'learning_rate': 2.95375e-05, 'epoch': 0.46}\n",
            "{'loss': 3.1154, 'grad_norm': 6.384582042694092, 'learning_rate': 2.938125e-05, 'epoch': 0.46}\n",
            "{'loss': 3.0792, 'grad_norm': 7.020155429840088, 'learning_rate': 2.9225000000000002e-05, 'epoch': 0.46}\n",
            "{'loss': 3.1255, 'grad_norm': 6.45257043838501, 'learning_rate': 2.9068750000000002e-05, 'epoch': 0.47}\n",
            "{'loss': 3.1095, 'grad_norm': 6.381531715393066, 'learning_rate': 2.8912500000000005e-05, 'epoch': 0.47}\n",
            "{'loss': 3.1183, 'grad_norm': 6.976809501647949, 'learning_rate': 2.875625e-05, 'epoch': 0.47}\n",
            "{'loss': 3.1003, 'grad_norm': 6.70000696182251, 'learning_rate': 2.86e-05, 'epoch': 0.48}\n",
            "{'loss': 3.0817, 'grad_norm': 6.998327255249023, 'learning_rate': 2.8443750000000004e-05, 'epoch': 0.48}\n",
            "{'loss': 3.1, 'grad_norm': 6.516801834106445, 'learning_rate': 2.82875e-05, 'epoch': 0.49}\n",
            "{'loss': 3.1381, 'grad_norm': 6.708960056304932, 'learning_rate': 2.8131250000000003e-05, 'epoch': 0.49}\n",
            "{'loss': 3.0478, 'grad_norm': 6.915759086608887, 'learning_rate': 2.7975000000000002e-05, 'epoch': 0.49}\n",
            "{'loss': 3.0872, 'grad_norm': 6.719376564025879, 'learning_rate': 2.781875e-05, 'epoch': 0.5}\n",
            "{'loss': 3.0846, 'grad_norm': 6.631194114685059, 'learning_rate': 2.76625e-05, 'epoch': 0.5}\n",
            "{'loss': 3.0723, 'grad_norm': 6.769970893859863, 'learning_rate': 2.750625e-05, 'epoch': 0.5}\n",
            "{'loss': 3.1042, 'grad_norm': 6.306298732757568, 'learning_rate': 2.7350000000000004e-05, 'epoch': 0.51}\n",
            "{'loss': 3.0892, 'grad_norm': 6.466765403747559, 'learning_rate': 2.719375e-05, 'epoch': 0.51}\n",
            "{'loss': 3.0503, 'grad_norm': 6.556395530700684, 'learning_rate': 2.70375e-05, 'epoch': 0.51}\n",
            "{'loss': 3.1434, 'grad_norm': 6.648149013519287, 'learning_rate': 2.6881250000000003e-05, 'epoch': 0.52}\n",
            "{'loss': 3.0944, 'grad_norm': 7.073908805847168, 'learning_rate': 2.6725e-05, 'epoch': 0.52}\n",
            "{'loss': 3.1266, 'grad_norm': 6.584436893463135, 'learning_rate': 2.6568750000000002e-05, 'epoch': 0.52}\n",
            "{'loss': 3.0816, 'grad_norm': 6.321007251739502, 'learning_rate': 2.64125e-05, 'epoch': 0.53}\n",
            "{'loss': 3.0465, 'grad_norm': 6.98941707611084, 'learning_rate': 2.6256249999999998e-05, 'epoch': 0.53}\n",
            "{'loss': 3.0791, 'grad_norm': 6.885699272155762, 'learning_rate': 2.61e-05, 'epoch': 0.53}\n",
            "{'loss': 3.0846, 'grad_norm': 7.157540321350098, 'learning_rate': 2.594375e-05, 'epoch': 0.54}\n",
            "{'loss': 3.1413, 'grad_norm': 6.5291571617126465, 'learning_rate': 2.5787500000000003e-05, 'epoch': 0.54}\n",
            "{'loss': 3.053, 'grad_norm': 6.819327354431152, 'learning_rate': 2.563125e-05, 'epoch': 0.54}\n",
            "{'loss': 3.0951, 'grad_norm': 7.150338172912598, 'learning_rate': 2.5475e-05, 'epoch': 0.55}\n",
            "{'loss': 3.1026, 'grad_norm': 7.182808876037598, 'learning_rate': 2.5318750000000002e-05, 'epoch': 0.55}\n",
            "{'loss': 3.1154, 'grad_norm': 6.9874444007873535, 'learning_rate': 2.51625e-05, 'epoch': 0.55}\n",
            "{'loss': 3.0704, 'grad_norm': 6.586540222167969, 'learning_rate': 2.5006250000000005e-05, 'epoch': 0.56}\n",
            " 50% 4000/8000 [54:11<53:03,  1.26it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 50\n",
            "  Batch size = 16\n",
            "\n",
            "  0% 0/4 [00:00<?, ?it/s]\u001b[A\n",
            " 50% 2/4 [00:03<00:03,  1.90s/it]\u001b[A\n",
            " 75% 3/4 [00:07<00:02,  2.53s/it]\u001b[A\n",
            "                                       \n",
            "\u001b[A{'eval_rouge-1': 32.837924, 'eval_rouge-2': 7.486112, 'eval_rouge-l': 25.066905999999996, 'eval_bleu-4': 0.04066636766874594, 'eval_runtime': 21.5843, 'eval_samples_per_second': 2.316, 'eval_steps_per_second': 0.185, 'epoch': 0.56}\n",
            " 50% 4000/8000 [54:32<53:03,  1.26it/s]\n",
            "100% 4/4 [00:10<00:00,  2.68s/it]\u001b[A\n",
            "                                 \u001b[ASaving model checkpoint to ./output/tmp-checkpoint-4000\n",
            "/usr/local/lib/python3.10/dist-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in models/THUDM/chatglm3-6b - will assume that the vocabulary was not modified.\n",
            "  warnings.warn(\n",
            "{'loss': 3.0621, 'grad_norm': 6.706821441650391, 'learning_rate': 2.485e-05, 'epoch': 0.56}\n",
            "{'loss': 3.0098, 'grad_norm': 6.169702529907227, 'learning_rate': 2.469375e-05, 'epoch': 0.57}\n",
            "{'loss': 3.0546, 'grad_norm': 6.8483686447143555, 'learning_rate': 2.4537500000000004e-05, 'epoch': 0.57}\n",
            "{'loss': 3.0947, 'grad_norm': 6.9041972160339355, 'learning_rate': 2.438125e-05, 'epoch': 0.57}\n",
            "{'loss': 3.0731, 'grad_norm': 7.246660232543945, 'learning_rate': 2.4225e-05, 'epoch': 0.58}\n",
            "{'loss': 3.0447, 'grad_norm': 6.57277250289917, 'learning_rate': 2.4068750000000002e-05, 'epoch': 0.58}\n",
            "{'loss': 3.1232, 'grad_norm': 6.502310276031494, 'learning_rate': 2.3912500000000002e-05, 'epoch': 0.58}\n",
            "{'loss': 3.0971, 'grad_norm': 6.870279312133789, 'learning_rate': 2.375625e-05, 'epoch': 0.59}\n",
            "{'loss': 3.0854, 'grad_norm': 7.686123371124268, 'learning_rate': 2.36e-05, 'epoch': 0.59}\n",
            "{'loss': 3.1229, 'grad_norm': 6.572368144989014, 'learning_rate': 2.344375e-05, 'epoch': 0.59}\n",
            "{'loss': 3.0987, 'grad_norm': 6.925757884979248, 'learning_rate': 2.32875e-05, 'epoch': 0.6}\n",
            "{'loss': 3.0554, 'grad_norm': 7.372351169586182, 'learning_rate': 2.3131250000000003e-05, 'epoch': 0.6}\n",
            "{'loss': 3.0402, 'grad_norm': 6.925522804260254, 'learning_rate': 2.2975000000000003e-05, 'epoch': 0.6}\n",
            "{'loss': 3.0949, 'grad_norm': 6.533478260040283, 'learning_rate': 2.281875e-05, 'epoch': 0.61}\n",
            "{'loss': 3.1225, 'grad_norm': 6.785353183746338, 'learning_rate': 2.2662500000000002e-05, 'epoch': 0.61}\n",
            "{'loss': 3.057, 'grad_norm': 6.563967227935791, 'learning_rate': 2.250625e-05, 'epoch': 0.61}\n",
            "{'loss': 3.0546, 'grad_norm': 6.773956298828125, 'learning_rate': 2.235e-05, 'epoch': 0.62}\n",
            "{'loss': 3.0955, 'grad_norm': 7.723349094390869, 'learning_rate': 2.219375e-05, 'epoch': 0.62}\n",
            "{'loss': 3.102, 'grad_norm': 6.6674370765686035, 'learning_rate': 2.20375e-05, 'epoch': 0.62}\n",
            "{'loss': 3.0534, 'grad_norm': 6.559829235076904, 'learning_rate': 2.188125e-05, 'epoch': 0.63}\n",
            "{'loss': 3.1511, 'grad_norm': 6.226430892944336, 'learning_rate': 2.1725e-05, 'epoch': 0.63}\n",
            "{'loss': 3.1034, 'grad_norm': 6.651580810546875, 'learning_rate': 2.1568750000000002e-05, 'epoch': 0.64}\n",
            "{'loss': 3.0933, 'grad_norm': 6.881508827209473, 'learning_rate': 2.1412500000000002e-05, 'epoch': 0.64}\n",
            "{'loss': 3.0688, 'grad_norm': 7.033613204956055, 'learning_rate': 2.1256249999999998e-05, 'epoch': 0.64}\n",
            "{'loss': 3.0932, 'grad_norm': 6.43912410736084, 'learning_rate': 2.11e-05, 'epoch': 0.65}\n",
            "{'loss': 3.0751, 'grad_norm': 6.894386291503906, 'learning_rate': 2.094375e-05, 'epoch': 0.65}\n",
            "{'loss': 3.0634, 'grad_norm': 6.685389995574951, 'learning_rate': 2.07875e-05, 'epoch': 0.65}\n",
            "{'loss': 3.0766, 'grad_norm': 6.756799221038818, 'learning_rate': 2.06375e-05, 'epoch': 0.66}\n",
            "{'loss': 3.1082, 'grad_norm': 6.753198146820068, 'learning_rate': 2.0481250000000003e-05, 'epoch': 0.66}\n",
            "{'loss': 3.0507, 'grad_norm': 6.745919704437256, 'learning_rate': 2.0325e-05, 'epoch': 0.66}\n",
            "{'loss': 3.0719, 'grad_norm': 6.28759241104126, 'learning_rate': 2.016875e-05, 'epoch': 0.67}\n",
            "{'loss': 3.0554, 'grad_norm': 7.310023784637451, 'learning_rate': 2.0012500000000002e-05, 'epoch': 0.67}\n",
            "{'loss': 3.074, 'grad_norm': 6.644845962524414, 'learning_rate': 1.985625e-05, 'epoch': 0.67}\n",
            "{'loss': 3.0445, 'grad_norm': 6.894899845123291, 'learning_rate': 1.97e-05, 'epoch': 0.68}\n",
            "{'loss': 3.0473, 'grad_norm': 6.658076286315918, 'learning_rate': 1.954375e-05, 'epoch': 0.68}\n",
            "{'loss': 3.0429, 'grad_norm': 6.862735748291016, 'learning_rate': 1.93875e-05, 'epoch': 0.68}\n",
            "{'loss': 3.1042, 'grad_norm': 7.391506195068359, 'learning_rate': 1.923125e-05, 'epoch': 0.69}\n",
            "{'loss': 3.0724, 'grad_norm': 6.91941499710083, 'learning_rate': 1.9075000000000003e-05, 'epoch': 0.69}\n",
            "{'loss': 3.0705, 'grad_norm': 6.477197170257568, 'learning_rate': 1.8918750000000002e-05, 'epoch': 0.69}\n",
            "{'loss': 3.075, 'grad_norm': 6.819544315338135, 'learning_rate': 1.87625e-05, 'epoch': 0.7}\n",
            " 62% 5000/8000 [1:07:45<38:21,  1.30it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 50\n",
            "  Batch size = 16\n",
            "\n",
            "  0% 0/4 [00:00<?, ?it/s]\u001b[A\n",
            " 50% 2/4 [00:10<00:10,  5.36s/it]\u001b[A\n",
            " 75% 3/4 [00:14<00:04,  4.86s/it]\u001b[A\n",
            "                                         \n",
            "\u001b[A{'eval_rouge-1': 33.509814, 'eval_rouge-2': 7.6514, 'eval_rouge-l': 25.111008, 'eval_bleu-4': 0.035119048229321964, 'eval_runtime': 37.0826, 'eval_samples_per_second': 1.348, 'eval_steps_per_second': 0.108, 'epoch': 0.7}\n",
            " 62% 5000/8000 [1:08:22<38:21,  1.30it/s]\n",
            "100% 4/4 [00:25<00:00,  7.02s/it]\u001b[A\n",
            "                                 \u001b[ASaving model checkpoint to ./output/tmp-checkpoint-5000\n",
            "/usr/local/lib/python3.10/dist-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in models/THUDM/chatglm3-6b - will assume that the vocabulary was not modified.\n",
            "  warnings.warn(\n",
            "{'loss': 3.0829, 'grad_norm': 6.720066070556641, 'learning_rate': 1.860625e-05, 'epoch': 0.7}\n",
            "{'loss': 3.0528, 'grad_norm': 6.733827114105225, 'learning_rate': 1.845e-05, 'epoch': 0.71}\n",
            "{'loss': 3.1307, 'grad_norm': 6.803452491760254, 'learning_rate': 1.829375e-05, 'epoch': 0.71}\n",
            "{'loss': 3.0547, 'grad_norm': 6.639063835144043, 'learning_rate': 1.81375e-05, 'epoch': 0.71}\n",
            "{'loss': 3.061, 'grad_norm': 7.115007400512695, 'learning_rate': 1.798125e-05, 'epoch': 0.72}\n",
            "{'loss': 3.0612, 'grad_norm': 7.023044586181641, 'learning_rate': 1.7825e-05, 'epoch': 0.72}\n",
            "{'loss': 3.0493, 'grad_norm': 6.8225178718566895, 'learning_rate': 1.766875e-05, 'epoch': 0.72}\n",
            "{'loss': 3.0762, 'grad_norm': 6.734564304351807, 'learning_rate': 1.7512500000000002e-05, 'epoch': 0.73}\n",
            "{'loss': 3.0843, 'grad_norm': 7.051535606384277, 'learning_rate': 1.7356250000000002e-05, 'epoch': 0.73}\n",
            "{'loss': 3.1255, 'grad_norm': 7.681034564971924, 'learning_rate': 1.7199999999999998e-05, 'epoch': 0.73}\n",
            "{'loss': 3.0825, 'grad_norm': 6.7253875732421875, 'learning_rate': 1.704375e-05, 'epoch': 0.74}\n",
            "{'loss': 3.0541, 'grad_norm': 7.2316694259643555, 'learning_rate': 1.68875e-05, 'epoch': 0.74}\n",
            "{'loss': 3.0353, 'grad_norm': 7.153750896453857, 'learning_rate': 1.673125e-05, 'epoch': 0.74}\n",
            "{'loss': 3.0473, 'grad_norm': 6.559616565704346, 'learning_rate': 1.6575000000000003e-05, 'epoch': 0.75}\n",
            "{'loss': 3.0698, 'grad_norm': 6.639342308044434, 'learning_rate': 1.641875e-05, 'epoch': 0.75}\n",
            "{'loss': 3.0921, 'grad_norm': 6.593416213989258, 'learning_rate': 1.62625e-05, 'epoch': 0.75}\n",
            "{'loss': 3.0468, 'grad_norm': 7.266806125640869, 'learning_rate': 1.6106250000000002e-05, 'epoch': 0.76}\n",
            "{'loss': 3.0739, 'grad_norm': 6.825833320617676, 'learning_rate': 1.595e-05, 'epoch': 0.76}\n",
            "{'loss': 3.0794, 'grad_norm': 7.010843753814697, 'learning_rate': 1.579375e-05, 'epoch': 0.76}\n",
            "{'loss': 3.0766, 'grad_norm': 6.757575511932373, 'learning_rate': 1.56375e-05, 'epoch': 0.77}\n",
            "{'loss': 3.072, 'grad_norm': 6.803675174713135, 'learning_rate': 1.548125e-05, 'epoch': 0.77}\n",
            "{'loss': 3.059, 'grad_norm': 6.876237869262695, 'learning_rate': 1.5325e-05, 'epoch': 0.77}\n",
            "{'loss': 3.0902, 'grad_norm': 6.5273213386535645, 'learning_rate': 1.5168750000000001e-05, 'epoch': 0.78}\n",
            "{'loss': 3.0515, 'grad_norm': 6.790352821350098, 'learning_rate': 1.5012500000000002e-05, 'epoch': 0.78}\n",
            "{'loss': 3.0893, 'grad_norm': 7.398083686828613, 'learning_rate': 1.4856249999999999e-05, 'epoch': 0.79}\n",
            "{'loss': 3.0397, 'grad_norm': 6.737329483032227, 'learning_rate': 1.47e-05, 'epoch': 0.79}\n",
            "{'loss': 3.0427, 'grad_norm': 7.047488689422607, 'learning_rate': 1.4543750000000001e-05, 'epoch': 0.79}\n",
            "{'loss': 3.0895, 'grad_norm': 7.010128974914551, 'learning_rate': 1.43875e-05, 'epoch': 0.8}\n",
            "{'loss': 3.0302, 'grad_norm': 7.123437881469727, 'learning_rate': 1.4231250000000002e-05, 'epoch': 0.8}\n",
            "{'loss': 3.0487, 'grad_norm': 6.731768608093262, 'learning_rate': 1.4075e-05, 'epoch': 0.8}\n",
            "{'loss': 3.0838, 'grad_norm': 7.536762237548828, 'learning_rate': 1.391875e-05, 'epoch': 0.81}\n",
            "{'loss': 3.0687, 'grad_norm': 6.886401176452637, 'learning_rate': 1.37625e-05, 'epoch': 0.81}\n",
            "{'loss': 3.0604, 'grad_norm': 7.571900367736816, 'learning_rate': 1.360625e-05, 'epoch': 0.81}\n",
            "{'loss': 3.0558, 'grad_norm': 7.201921463012695, 'learning_rate': 1.3450000000000002e-05, 'epoch': 0.82}\n",
            "{'loss': 3.0731, 'grad_norm': 7.174124717712402, 'learning_rate': 1.329375e-05, 'epoch': 0.82}\n",
            "{'loss': 3.0503, 'grad_norm': 6.742583274841309, 'learning_rate': 1.31375e-05, 'epoch': 0.82}\n",
            "{'loss': 3.0889, 'grad_norm': 7.099446773529053, 'learning_rate': 1.298125e-05, 'epoch': 0.83}\n",
            "{'loss': 3.0909, 'grad_norm': 7.52410364151001, 'learning_rate': 1.2825000000000002e-05, 'epoch': 0.83}\n",
            "{'loss': 3.0413, 'grad_norm': 7.525298118591309, 'learning_rate': 1.2668750000000001e-05, 'epoch': 0.83}\n",
            "{'loss': 3.0311, 'grad_norm': 7.166632175445557, 'learning_rate': 1.25125e-05, 'epoch': 0.84}\n",
            " 75% 6000/8000 [1:21:34<26:51,  1.24it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 50\n",
            "  Batch size = 16\n",
            "\n",
            "  0% 0/4 [00:00<?, ?it/s]\u001b[A\n",
            " 50% 2/4 [00:03<00:03,  1.98s/it]\u001b[A\n",
            " 75% 3/4 [00:14<00:05,  5.58s/it]\u001b[A\n",
            "                                         \n",
            "\u001b[A{'eval_rouge-1': 33.519358000000004, 'eval_rouge-2': 8.044804, 'eval_rouge-l': 25.51553, 'eval_bleu-4': 0.03862392973933027, 'eval_runtime': 28.644, 'eval_samples_per_second': 1.746, 'eval_steps_per_second': 0.14, 'epoch': 0.84}\n",
            " 75% 6000/8000 [1:22:03<26:51,  1.24it/s]\n",
            "100% 4/4 [00:17<00:00,  4.46s/it]\u001b[A\n",
            "                                 \u001b[ASaving model checkpoint to ./output/tmp-checkpoint-6000\n",
            "/usr/local/lib/python3.10/dist-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in models/THUDM/chatglm3-6b - will assume that the vocabulary was not modified.\n",
            "  warnings.warn(\n",
            "{'loss': 3.0253, 'grad_norm': 7.443760871887207, 'learning_rate': 1.235625e-05, 'epoch': 0.84}\n",
            "{'loss': 3.0379, 'grad_norm': 6.737528324127197, 'learning_rate': 1.22e-05, 'epoch': 0.84}\n",
            "{'loss': 3.1159, 'grad_norm': 6.699151515960693, 'learning_rate': 1.2043750000000001e-05, 'epoch': 0.85}\n",
            "{'loss': 3.0314, 'grad_norm': 7.416630744934082, 'learning_rate': 1.18875e-05, 'epoch': 0.85}\n",
            "{'loss': 3.0593, 'grad_norm': 7.177070140838623, 'learning_rate': 1.173125e-05, 'epoch': 0.86}\n",
            "{'loss': 3.0338, 'grad_norm': 7.051250457763672, 'learning_rate': 1.1575000000000002e-05, 'epoch': 0.86}\n",
            "{'loss': 3.0456, 'grad_norm': 7.287434101104736, 'learning_rate': 1.141875e-05, 'epoch': 0.86}\n",
            "{'loss': 3.0744, 'grad_norm': 7.375473499298096, 'learning_rate': 1.1262500000000001e-05, 'epoch': 0.87}\n",
            "{'loss': 3.0597, 'grad_norm': 6.986913681030273, 'learning_rate': 1.110625e-05, 'epoch': 0.87}\n",
            "{'loss': 3.0694, 'grad_norm': 6.990248203277588, 'learning_rate': 1.095e-05, 'epoch': 0.87}\n",
            "{'loss': 3.0373, 'grad_norm': 7.186672687530518, 'learning_rate': 1.0793750000000001e-05, 'epoch': 0.88}\n",
            "{'loss': 3.037, 'grad_norm': 7.677206516265869, 'learning_rate': 1.0637500000000001e-05, 'epoch': 0.88}\n",
            "{'loss': 3.0504, 'grad_norm': 6.765493392944336, 'learning_rate': 1.048125e-05, 'epoch': 0.88}\n",
            "{'loss': 3.075, 'grad_norm': 7.244637489318848, 'learning_rate': 1.0325e-05, 'epoch': 0.89}\n",
            "{'loss': 3.0601, 'grad_norm': 7.347101211547852, 'learning_rate': 1.016875e-05, 'epoch': 0.89}\n",
            "{'loss': 3.0307, 'grad_norm': 6.569877624511719, 'learning_rate': 1.0012500000000001e-05, 'epoch': 0.89}\n",
            "{'loss': 3.0651, 'grad_norm': 7.180483818054199, 'learning_rate': 9.85625e-06, 'epoch': 0.9}\n",
            "{'loss': 3.0491, 'grad_norm': 6.82769250869751, 'learning_rate': 9.7e-06, 'epoch': 0.9}\n",
            "{'loss': 3.0823, 'grad_norm': 6.981909275054932, 'learning_rate': 9.54375e-06, 'epoch': 0.9}\n",
            "{'loss': 3.0407, 'grad_norm': 7.168030261993408, 'learning_rate': 9.387500000000001e-06, 'epoch': 0.91}\n",
            "{'loss': 3.037, 'grad_norm': 6.899554252624512, 'learning_rate': 9.23125e-06, 'epoch': 0.91}\n",
            "{'loss': 3.091, 'grad_norm': 6.531689643859863, 'learning_rate': 9.075e-06, 'epoch': 0.91}\n",
            "{'loss': 3.0612, 'grad_norm': 7.0054402351379395, 'learning_rate': 8.91875e-06, 'epoch': 0.92}\n",
            "{'loss': 3.0712, 'grad_norm': 6.912726402282715, 'learning_rate': 8.7625e-06, 'epoch': 0.92}\n",
            "{'loss': 3.0988, 'grad_norm': 7.0505170822143555, 'learning_rate': 8.60625e-06, 'epoch': 0.92}\n",
            "{'loss': 3.0559, 'grad_norm': 8.086052894592285, 'learning_rate': 8.45e-06, 'epoch': 0.93}\n",
            "{'loss': 3.0546, 'grad_norm': 6.974052429199219, 'learning_rate': 8.29375e-06, 'epoch': 0.93}\n",
            "{'loss': 3.0413, 'grad_norm': 7.1195855140686035, 'learning_rate': 8.137500000000001e-06, 'epoch': 0.94}\n",
            "{'loss': 3.0288, 'grad_norm': 6.865273952484131, 'learning_rate': 7.98125e-06, 'epoch': 0.94}\n",
            "{'loss': 3.066, 'grad_norm': 6.929889678955078, 'learning_rate': 7.825e-06, 'epoch': 0.94}\n",
            "{'loss': 3.0359, 'grad_norm': 7.12838077545166, 'learning_rate': 7.668750000000002e-06, 'epoch': 0.95}\n",
            "{'loss': 3.0406, 'grad_norm': 7.555715084075928, 'learning_rate': 7.5125000000000005e-06, 'epoch': 0.95}\n",
            "{'loss': 3.0369, 'grad_norm': 7.180952548980713, 'learning_rate': 7.356250000000001e-06, 'epoch': 0.95}\n",
            "{'loss': 3.0314, 'grad_norm': 7.067104339599609, 'learning_rate': 7.2e-06, 'epoch': 0.96}\n",
            "{'loss': 3.0558, 'grad_norm': 7.579901695251465, 'learning_rate': 7.04375e-06, 'epoch': 0.96}\n",
            "{'loss': 3.0529, 'grad_norm': 7.769797325134277, 'learning_rate': 6.8875000000000005e-06, 'epoch': 0.96}\n",
            "{'loss': 3.0127, 'grad_norm': 7.096338748931885, 'learning_rate': 6.737500000000001e-06, 'epoch': 0.97}\n",
            "{'loss': 3.061, 'grad_norm': 7.595314025878906, 'learning_rate': 6.58125e-06, 'epoch': 0.97}\n",
            "{'loss': 3.0262, 'grad_norm': 7.089076042175293, 'learning_rate': 6.425e-06, 'epoch': 0.97}\n",
            "{'loss': 3.0175, 'grad_norm': 7.068506240844727, 'learning_rate': 6.26875e-06, 'epoch': 0.98}\n",
            " 88% 7000/8000 [1:35:18<13:27,  1.24it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 50\n",
            "  Batch size = 16\n",
            "\n",
            "  0% 0/4 [00:00<?, ?it/s]\u001b[A\n",
            " 50% 2/4 [00:04<00:04,  2.43s/it]\u001b[A\n",
            " 75% 3/4 [00:08<00:02,  2.85s/it]\u001b[A\n",
            "                                         \n",
            "\u001b[A{'eval_rouge-1': 34.163838, 'eval_rouge-2': 8.518672, 'eval_rouge-l': 26.49012, 'eval_bleu-4': 0.04132288805703942, 'eval_runtime': 14.7, 'eval_samples_per_second': 3.401, 'eval_steps_per_second': 0.272, 'epoch': 0.98}\n",
            " 88% 7000/8000 [1:35:33<13:27,  1.24it/s]\n",
            "100% 4/4 [00:10<00:00,  2.65s/it]\u001b[A\n",
            "                                 \u001b[ASaving model checkpoint to ./output/tmp-checkpoint-7000\n",
            "/usr/local/lib/python3.10/dist-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in models/THUDM/chatglm3-6b - will assume that the vocabulary was not modified.\n",
            "  warnings.warn(\n",
            "{'loss': 3.0072, 'grad_norm': 7.547343730926514, 'learning_rate': 6.1125e-06, 'epoch': 0.98}\n",
            "{'loss': 3.063, 'grad_norm': 7.4792280197143555, 'learning_rate': 5.95625e-06, 'epoch': 0.98}\n",
            "{'loss': 3.0574, 'grad_norm': 7.037683010101318, 'learning_rate': 5.8e-06, 'epoch': 0.99}\n",
            "{'loss': 3.0175, 'grad_norm': 7.853835105895996, 'learning_rate': 5.643750000000001e-06, 'epoch': 0.99}\n",
            "{'loss': 3.0698, 'grad_norm': 7.513693332672119, 'learning_rate': 5.4875e-06, 'epoch': 0.99}\n",
            "{'loss': 3.0502, 'grad_norm': 7.491745471954346, 'learning_rate': 5.33125e-06, 'epoch': 1.0}\n",
            " 90% 7162/8000 [1:37:41<10:55,  1.28it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "{'loss': 3.0221, 'grad_norm': 6.929961204528809, 'learning_rate': 5.175e-06, 'epoch': 1.0}\n",
            "{'loss': 3.04, 'grad_norm': 7.7233099937438965, 'learning_rate': 5.018750000000001e-06, 'epoch': 1.01}\n",
            "{'loss': 3.0187, 'grad_norm': 7.554509162902832, 'learning_rate': 4.8625000000000005e-06, 'epoch': 1.01}\n",
            "{'loss': 2.9872, 'grad_norm': 7.271574974060059, 'learning_rate': 4.70625e-06, 'epoch': 1.01}\n",
            "{'loss': 3.0258, 'grad_norm': 7.418499946594238, 'learning_rate': 4.5500000000000005e-06, 'epoch': 1.02}\n",
            "{'loss': 3.005, 'grad_norm': 7.169942855834961, 'learning_rate': 4.39375e-06, 'epoch': 1.02}\n",
            "{'loss': 2.9888, 'grad_norm': 7.718091011047363, 'learning_rate': 4.2375000000000005e-06, 'epoch': 1.02}\n",
            "{'loss': 3.0124, 'grad_norm': 7.047276496887207, 'learning_rate': 4.08125e-06, 'epoch': 1.03}\n",
            "{'loss': 3.0173, 'grad_norm': 7.40697717666626, 'learning_rate': 3.9250000000000005e-06, 'epoch': 1.03}\n",
            "{'loss': 3.0602, 'grad_norm': 7.033374309539795, 'learning_rate': 3.76875e-06, 'epoch': 1.03}\n",
            "{'loss': 2.9728, 'grad_norm': 7.6466169357299805, 'learning_rate': 3.6124999999999997e-06, 'epoch': 1.04}\n",
            "{'loss': 3.0422, 'grad_norm': 7.1010284423828125, 'learning_rate': 3.4562500000000006e-06, 'epoch': 1.04}\n",
            "{'loss': 3.0333, 'grad_norm': 7.296413421630859, 'learning_rate': 3.3e-06, 'epoch': 1.04}\n",
            "{'loss': 3.0028, 'grad_norm': 7.62086820602417, 'learning_rate': 3.14375e-06, 'epoch': 1.05}\n",
            "{'loss': 3.0204, 'grad_norm': 7.557666301727295, 'learning_rate': 2.9875e-06, 'epoch': 1.05}\n",
            "{'loss': 3.0165, 'grad_norm': 7.265463352203369, 'learning_rate': 2.83125e-06, 'epoch': 1.05}\n",
            "{'loss': 3.0515, 'grad_norm': 7.109556674957275, 'learning_rate': 2.6750000000000002e-06, 'epoch': 1.06}\n",
            "{'loss': 3.0356, 'grad_norm': 7.275899887084961, 'learning_rate': 2.5187500000000002e-06, 'epoch': 1.06}\n",
            "{'loss': 3.0365, 'grad_norm': 6.979001998901367, 'learning_rate': 2.3625000000000003e-06, 'epoch': 1.06}\n",
            "{'loss': 3.0347, 'grad_norm': 7.159457683563232, 'learning_rate': 2.20625e-06, 'epoch': 1.07}\n",
            "{'loss': 3.0036, 'grad_norm': 7.5897698402404785, 'learning_rate': 2.0500000000000003e-06, 'epoch': 1.07}\n",
            "{'loss': 3.0234, 'grad_norm': 7.658105373382568, 'learning_rate': 1.89375e-06, 'epoch': 1.08}\n",
            "{'loss': 3.0125, 'grad_norm': 7.263454914093018, 'learning_rate': 1.7375000000000003e-06, 'epoch': 1.08}\n",
            "{'loss': 3.018, 'grad_norm': 7.208878993988037, 'learning_rate': 1.5812500000000001e-06, 'epoch': 1.08}\n",
            "{'loss': 3.0065, 'grad_norm': 7.741599082946777, 'learning_rate': 1.4250000000000001e-06, 'epoch': 1.09}\n",
            "{'loss': 3.0097, 'grad_norm': 7.645491600036621, 'learning_rate': 1.2687500000000001e-06, 'epoch': 1.09}\n",
            "{'loss': 3.026, 'grad_norm': 7.225083351135254, 'learning_rate': 1.1125e-06, 'epoch': 1.09}\n",
            "{'loss': 3.0569, 'grad_norm': 6.495636463165283, 'learning_rate': 9.5625e-07, 'epoch': 1.1}\n",
            "{'loss': 3.0412, 'grad_norm': 7.361515045166016, 'learning_rate': 8.000000000000001e-07, 'epoch': 1.1}\n",
            "{'loss': 3.0092, 'grad_norm': 7.14296817779541, 'learning_rate': 6.4375e-07, 'epoch': 1.1}\n",
            "{'loss': 2.9842, 'grad_norm': 7.491602897644043, 'learning_rate': 4.875e-07, 'epoch': 1.11}\n",
            "{'loss': 3.0607, 'grad_norm': 7.561606407165527, 'learning_rate': 3.3125e-07, 'epoch': 1.11}\n",
            "{'loss': 3.0337, 'grad_norm': 7.02121639251709, 'learning_rate': 1.7500000000000002e-07, 'epoch': 1.11}\n",
            "{'loss': 3.0103, 'grad_norm': 7.3705244064331055, 'learning_rate': 1.8750000000000002e-08, 'epoch': 1.12}\n",
            "100% 8000/8000 [1:48:49<00:00,  1.25it/s]***** Running Evaluation *****\n",
            "  Num examples = 50\n",
            "  Batch size = 16\n",
            "\n",
            "  0% 0/4 [00:00<?, ?it/s]\u001b[A\n",
            " 50% 2/4 [00:10<00:10,  5.32s/it]\u001b[A\n",
            " 75% 3/4 [00:13<00:04,  4.47s/it]\u001b[A\n",
            "                                         \n",
            "\u001b[A{'eval_rouge-1': 33.025688, 'eval_rouge-2': 7.92154, 'eval_rouge-l': 26.046530000000004, 'eval_bleu-4': 0.03948887202244507, 'eval_runtime': 20.6878, 'eval_samples_per_second': 2.417, 'eval_steps_per_second': 0.193, 'epoch': 1.12}\n",
            "100% 8000/8000 [1:49:09<00:00,  1.25it/s]\n",
            "100% 4/4 [00:16<00:00,  3.65s/it]\u001b[A\n",
            "                                 \u001b[ASaving model checkpoint to ./output/tmp-checkpoint-8000\n",
            "/usr/local/lib/python3.10/dist-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in models/THUDM/chatglm3-6b - will assume that the vocabulary was not modified.\n",
            "  warnings.warn(\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "{'train_runtime': 6550.1313, 'train_samples_per_second': 19.542, 'train_steps_per_second': 1.221, 'train_loss': 3.123331298828125, 'epoch': 1.12}\n",
            "100% 8000/8000 [1:49:10<00:00,  1.22it/s]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "***** Running Prediction *****\n",
            "  Num examples = 1070\n",
            "  Batch size = 16\n",
            "100% 67/67 [06:06<00:00,  5.48s/it]\n"
          ]
        }
      ],
      "source": [
        "!CUDA_VISIBLE_DEVICES=0 python /content/drive/MyDrive/data/finetune_demo/finetune_hf.py  /content/drive/MyDrive/data/finetune_demo/AdvertiseGen_fix  models/THUDM/chatglm3-6b  /content/drive/MyDrive/data/finetune_demo/configs/lora.yaml"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-18T06:44:56.043246Z",
          "start_time": "2024-01-18T05:05:28.425374Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "17c87410a24d844f",
        "outputId": "87ab358f-9079-4f43-de9f-3c503ed953ff"
      },
      "id": "17c87410a24d844f"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. 使用微调的数据集进行推理\n",
        "在完成微调任务之后，我们可以查看到 `output` 文件夹下多了很多个`checkpoint-*`的文件夹，这些文件夹代表了训练的轮数。\n",
        "我们选择最后一轮的微调权重，并使用inference进行导入。"
      ],
      "metadata": {
        "collapsed": false,
        "id": "d9418f6c5c264601"
      },
      "id": "d9418f6c5c264601"
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "checkpoint-1000  checkpoint-2500  checkpoint-500   checkpoint-7000\n",
            "checkpoint-1500  checkpoint-3000  checkpoint-5000  checkpoint-8000\n",
            "checkpoint-2000  checkpoint-4000  checkpoint-6000  runs\n"
          ]
        }
      ],
      "source": [
        "!ls output/"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-18T07:03:19.390123Z",
          "start_time": "2024-01-18T07:03:19.246666Z"
        },
        "id": "3f22b735175e1c0d",
        "outputId": "598630e6-f8a6-4666-c845-54673f084243",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "3f22b735175e1c0d"
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r output/checkpoint-8000/ /content/drive/MyDrive/data/finetune_demo/"
      ],
      "metadata": {
        "id": "vB7GckB3tQo-"
      },
      "id": "vB7GckB3tQo-",
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading checkpoint shards: 100% 3/3 [00:03<00:00,  1.31s/it]\n",
            "Setting eos_token is not supported, use the default one.\n",
            "Setting pad_token is not supported, use the default one.\n",
            "Setting unk_token is not supported, use the default one.\n",
            "2024-04-04 02:13:05.304438: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-04-04 02:13:05.304493: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-04-04 02:13:05.305785: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-04-04 02:13:06.505854: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "网纱拼接的连衣裙，穿着时尚美丽，轻松穿出性感优雅。网纱面料透视效果明显，透着几分性感诱惑，木耳边压褶的裙摆，不规则剪裁，穿着灵动有型。套头式的款式，简洁大方，上身效果很显瘦。拉链开襟的设计，方便穿脱。\n"
          ]
        }
      ],
      "source": [
        "!CUDA_VISIBLE_DEVICES=0 python /content/drive/MyDrive/data/finetune_demo/inference_hf.py  output/checkpoint-8000/ --prompt \"类型#裙*版型#显瘦*材质#网纱*风格#性感*裙型#百褶*裙下摆#压褶*裙长#连衣裙*裙衣门襟#拉链*裙衣门襟#套头*裙款式#拼接*裙款式#拉链*裙款式#木耳边*裙款式#抽褶*裙款式#不规则\""
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-01-18T07:08:13.616364Z",
          "start_time": "2024-01-18T07:07:07.346906Z"
        },
        "id": "5060015c24e97ae",
        "outputId": "8f10bf91-3fcf-4749-d705-d7e7511fc255",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "5060015c24e97ae"
    },
    {
      "cell_type": "code",
      "source": [
        "!CUDA_VISIBLE_DEVICES=0 python /content/drive/MyDrive/data/finetune_demo/inference_hf.py /content/drive/MyDrive/data/finetune_demo/checkpoint-8000/ --prompt \"类型#裙*版型#显瘦*材质#网纱*风格#性感*裙型#百褶*裙下摆#压褶*裙长#连衣裙*裙衣门襟#拉链*裙衣门襟#套头*裙款式#拼接*裙款式#拉链*裙款式#木耳边*裙款式#抽褶*裙款式#不规则\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3hQCRX3w4c8Q",
        "outputId": "875103f6-e7a7-48d6-d83c-d300ddf4071f"
      },
      "id": "3hQCRX3w4c8Q",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading checkpoint shards: 100% 3/3 [00:03<00:00,  1.31s/it]\n",
            "Setting eos_token is not supported, use the default one.\n",
            "Setting pad_token is not supported, use the default one.\n",
            "Setting unk_token is not supported, use the default one.\n",
            "2024-04-04 02:13:52.982555: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-04-04 02:13:52.982610: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-04-04 02:13:52.984249: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-04-04 02:13:54.175830: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "这款连衣裙整体采用网纱拼接设计，带来视觉上的朦胧感，营造浪漫神秘的气息，透着几分性感。套头设计，方便穿脱，同时修饰脖颈曲线，带来几分俏皮活力。压褶设计，不规则裙摆，行走间摇曳生姿，更显灵动感。下摆拼接木耳边设计，丰富层次感，带来视觉上的层次感，穿着显瘦。内里采用不规则压褶设计，不规则压褶，穿着舒适。拉链闭合设计，穿着方便，同时穿着舒适。\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!CUDA_VISIBLE_DEVICES=0 python /content/drive/MyDrive/data/finetune_demo/inference_hf.py /content/drive/MyDrive/data/finetune_demo/checkpoint-8000/ --prompt \"类型#T恤*版型#合身*材质#全棉*牛仔裤#休闲#自如#全家福*\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OkBMyU5G4u1X",
        "outputId": "bdf755d0-cd2e-43ca-9d37-3618022d4624"
      },
      "id": "OkBMyU5G4u1X",
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading checkpoint shards: 100% 3/3 [00:03<00:00,  1.31s/it]\n",
            "Setting eos_token is not supported, use the default one.\n",
            "Setting pad_token is not supported, use the default one.\n",
            "Setting unk_token is not supported, use the default one.\n",
            "2024-04-04 02:17:29.302777: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-04-04 02:17:29.302826: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-04-04 02:17:29.304667: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-04-04 02:17:30.492260: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "这款全棉牛仔裤，采用休闲版型，上身自如，不挑身材，无论是小宝还是大宝，都可以轻松驾驭。休闲的版型，上身更加自在舒适，不束缚身体。全棉材质，柔软亲肤，透气性好，穿起来更加舒适自在。全家人都可以穿，适合全家人福照拍摄。\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. 总结\n",
        "到此位置，我们就完成了使用单张 GPU Lora 来微调 ChatGLM3-6B 模型，使其能生产出更好的广告。\n",
        "在本章节中，你将会学会：\n",
        "+ 如何使用模型进行 Lora 微调\n",
        "+ 微调数据集的准备和对齐\n",
        "+ 使用微调的模型进行推理"
      ],
      "metadata": {
        "collapsed": false,
        "id": "18cd83087f096094"
      },
      "id": "18cd83087f096094"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c7904fb138d54f6cba16bc3eaac4edee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f6fcdb223eac4078a65625715e374f0d",
              "IPY_MODEL_45e85fcdb3ad44109653cc25bc477536",
              "IPY_MODEL_462d678630044a349ef0f3f1c57a1aeb"
            ],
            "layout": "IPY_MODEL_ef36a91ad58b43a5ae5a474c12b4e058"
          }
        },
        "f6fcdb223eac4078a65625715e374f0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_80350e8702404d2e9fbada30d410d203",
            "placeholder": "​",
            "style": "IPY_MODEL_44fad327810c460381bc6b9e1129c2bf",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "45e85fcdb3ad44109653cc25bc477536": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8398b08912ad4526b6b756c20b85764b",
            "max": 7,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7a2435fb8ea04811b1157e68c59f5be9",
            "value": 7
          }
        },
        "462d678630044a349ef0f3f1c57a1aeb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1f6d64fbd9a1485fa256bc216cb043cb",
            "placeholder": "​",
            "style": "IPY_MODEL_5b505a3461234fafb68c21cc003a0add",
            "value": " 7/7 [00:03&lt;00:00,  2.45it/s]"
          }
        },
        "ef36a91ad58b43a5ae5a474c12b4e058": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "80350e8702404d2e9fbada30d410d203": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "44fad327810c460381bc6b9e1129c2bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8398b08912ad4526b6b756c20b85764b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7a2435fb8ea04811b1157e68c59f5be9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1f6d64fbd9a1485fa256bc216cb043cb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5b505a3461234fafb68c21cc003a0add": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}